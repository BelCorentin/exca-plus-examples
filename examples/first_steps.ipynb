{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Understand and use exca in a very basic scenario: simply to create a simple model, config and cache it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseInfra.config of TaskInfra(folder='.cache/', cluster=None, logs='{folder}/logs/{user}/%j', job_name=None, timeout_min=None, nodes=1, tasks_per_node=1, cpus_per_task=None, gpus_per_node=None, mem_gb=None, slurm_constraint=None, slurm_partition=None, slurm_account=None, slurm_qos=None, slurm_use_srun=False, slurm_additional_parameters=None, conda_env=None, workdir=None, permissions=511, version='0', mode='cached', keep_in_ram=False)>\n",
      "4352.458846189906\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A minimalist example with sklearn to show how to develop and explore a model with exca.\n",
    "\"\"\"\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import pydantic\n",
    "import sys\n",
    "import exca\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class Dataset(pydantic.BaseModel):\n",
    "    n_samples: int = 100\n",
    "    noise: float = 0.1\n",
    "    random_state: int = 42\n",
    "    test_size: float = 0.2\n",
    "    model_config = pydantic.ConfigDict(extra=\"forbid\")\n",
    "\n",
    "    def get(self) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        # Generate synthetic data\n",
    "        X, y = make_regression(\n",
    "            n_samples=self.n_samples,\n",
    "            noise=self.noise,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        # Split into training and testing datasets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, \n",
    "            test_size=self.test_size, \n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "class Model(pydantic.BaseModel):\n",
    "    data: Dataset = Dataset()\n",
    "    alpha: float = 1.0\n",
    "    max_iter: int = 1000\n",
    "    infra: exca.TaskInfra = exca.TaskInfra(folder='.cache/', version='v1.0')\n",
    "\n",
    "    @infra.apply\n",
    "    def score(self):\n",
    "        # Get data\n",
    "        X_train, X_test, y_train, y_test = self.data.get()\n",
    "\n",
    "        # Train a Ridge regression model\n",
    "        print('Fit...')\n",
    "        model = Ridge(alpha=self.alpha, max_iter=self.max_iter)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        print('Score...')\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        return mse\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Validate config\n",
    "    basic_config = {\"alpha\": 1.0, \"max_iter\": 1000}\n",
    "    config = exca.ConfDict(basic_config)\n",
    "    model = Model(**config)\n",
    "    print(model.infra.config)\n",
    "\n",
    "    # Score\n",
    "    mse = model.score()\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m__main__.Model.score,0\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls .cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the scoring function: make it a new version !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseInfra.config of TaskInfra(folder='.cache/', cluster=None, logs='{folder}/logs/{user}/%j', job_name=None, timeout_min=None, nodes=1, tasks_per_node=1, cpus_per_task=None, gpus_per_node=None, mem_gb=None, slurm_constraint=None, slurm_partition=None, slurm_account=None, slurm_qos=None, slurm_use_srun=False, slurm_additional_parameters=None, conda_env=None, workdir=None, permissions=511, version='v2.0', mode='cached', keep_in_ram=False)>\n",
      "4501.658453980022\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Model(pydantic.BaseModel):\n",
    "    data: Dataset = Dataset()\n",
    "    alpha: float = 1.0\n",
    "    max_iter: int = 1000\n",
    "    infra: exca.TaskInfra = exca.TaskInfra(folder='.cache/', version='v2.0')\n",
    "\n",
    "    @infra.apply\n",
    "    def score(self):\n",
    "        # Get data\n",
    "        X_train, X_test, y_train, y_test = self.data.get()\n",
    "\n",
    "        # Train a Ridge regression model\n",
    "        print('Fit...')\n",
    "        # model = Ridge(alpha=self.alpha, max_iter=self.max_iter)\n",
    "\n",
    "        ## NEW VERSION: use not a Ridge model but a LinearRegression model\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        print('Score...')\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        return mse\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Validate config\n",
    "    basic_config = {\"alpha\": 1.0, \"max_iter\": 1000}\n",
    "    config = exca.ConfDict(basic_config)\n",
    "    model = Model(**config)\n",
    "    print(model.infra.config)\n",
    "\n",
    "    # Score\n",
    "    mse = model.score()\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m__main__.Model.score,0\u001b[0m/  \u001b[01;34m__main__.Model.score,v2.0\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls .cache/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
